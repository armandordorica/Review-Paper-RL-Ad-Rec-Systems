{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0660adb-74b4-4183-aefd-645e27971bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{thebibliography}{99}\\n\\\\bibitem{krizhevsky2012imagenet} Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E. {I}magenet classification with deep convolutional neural networks. \\\\textit{Advances in neural information processing systems}, 25, 2012.\\n\\n\\\\bibitem{Sutton1998} Richard S. Sutton and Andrew G. Barto. {R}einforcement {L}earning: {A}n {I}ntroduction. \\\\textit{}, 1998. MIT Press.\\n\\\\end{thebibliography}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bibtexparser.bparser import BibTexParser\n",
    "from bibtexparser.customization import homogenize_latex_encoding\n",
    "import bibtexparser\n",
    "\n",
    "# Simulating a small sample from user's provided bibtex for feasibility\n",
    "sample_bibtex = \"\"\"\n",
    "@article{krizhevsky2012imagenet,\n",
    "  title={Imagenet classification with deep convolutional neural networks},\n",
    "  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},\n",
    "  journal={Advances in neural information processing systems},\n",
    "  volume={25},\n",
    "  year={2012}\n",
    "}\n",
    "\n",
    "@book{Sutton1998,\n",
    "  author    = {Richard S. Sutton and Andrew G. Barto},\n",
    "  title     = {Reinforcement Learning: An Introduction},\n",
    "  year      = {1998},\n",
    "  publisher = {MIT Press},\n",
    "  edition   = {1st},\n",
    "  address   = {Cambridge, MA}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Parse the BibTeX string\n",
    "parser = BibTexParser(common_strings=True)\n",
    "parser.customization = homogenize_latex_encoding\n",
    "bib_database = bibtexparser.loads(sample_bibtex, parser=parser)\n",
    "\n",
    "# Generate LaTeX \\bibitem entries\n",
    "bibitems = []\n",
    "for entry in bib_database.entries:\n",
    "    key = entry.get(\"ID\", \"\")\n",
    "    authors = entry.get(\"author\", \"\").replace(\"\\n\", \" \")\n",
    "    title = entry.get(\"title\", \"\")\n",
    "    year = entry.get(\"year\", \"\")\n",
    "    journal = entry.get(\"journal\", entry.get(\"booktitle\", \"\"))\n",
    "    volume = entry.get(\"volume\", \"\")\n",
    "    pages = entry.get(\"pages\", \"\")\n",
    "    publisher = entry.get(\"publisher\", \"\")\n",
    "    bibitem = f\"\\\\bibitem{{{key}}} {authors}. {title}. \\\\textit{{{journal}}}\"\n",
    "    if volume:\n",
    "        bibitem += f\", {volume}\"\n",
    "    if pages:\n",
    "        bibitem += f\", {pages}\"\n",
    "    if year:\n",
    "        bibitem += f\", {year}\"\n",
    "    if publisher:\n",
    "        bibitem += f\". {publisher}\"\n",
    "    bibitem += \".\"\n",
    "    bibitems.append(bibitem)\n",
    "\n",
    "bibitems_text = \"\\\\begin{thebibliography}{99}\\n\" + \"\\n\\n\".join(bibitems) + \"\\n\\\\end{thebibliography}\"\n",
    "bibitems_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b952682-df03-4eb9-b9e7-40e0307d03dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{thebibliography}{99}\n",
      "\\bibitem{krizhevsky2012imagenet} Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E. {I}magenet classification with deep convolutional neural networks. \\textit{Advances in neural information processing systems}, 25, 2012.\n",
      "\n",
      "\\bibitem{Sutton1998} Richard S. Sutton and Andrew G. Barto. {R}einforcement {L}earning: {A}n {I}ntroduction. \\textit{}, 1998. MIT Press.\n",
      "\\end{thebibliography}\n"
     ]
    }
   ],
   "source": [
    "print(bibitems_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6808e9dc-0d33-4295-9821-f5e9d9e6e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All entries written to generated_bibitems.tex\n"
     ]
    }
   ],
   "source": [
    "from bibtexparser.bparser import BibTexParser\n",
    "from bibtexparser.customization import homogenize_latex_encoding\n",
    "import bibtexparser\n",
    "import os\n",
    "\n",
    "def format_entry(entry):\n",
    "    key = entry.get(\"ID\", \"\")\n",
    "    entry_type = entry.get(\"ENTRYTYPE\", \"\").lower()\n",
    "    author = entry.get(\"author\", \"\").replace(\"\\n\", \" \")\n",
    "    title = entry.get(\"title\", \"\")\n",
    "    year = entry.get(\"year\", \"\")\n",
    "    journal = entry.get(\"journal\", \"\")\n",
    "    booktitle = entry.get(\"booktitle\", \"\")\n",
    "    volume = entry.get(\"volume\", \"\")\n",
    "    pages = entry.get(\"pages\", \"\")\n",
    "    publisher = entry.get(\"publisher\", \"\")\n",
    "    organization = entry.get(\"organization\", \"\")\n",
    "    url = entry.get(\"url\", \"\")\n",
    "    note = entry.get(\"note\", \"\")\n",
    "\n",
    "    bibitem = f\"\\\\bibitem{{{key}}} {author}. {title}.\"\n",
    "\n",
    "    if entry_type == \"article\":\n",
    "        if journal:\n",
    "            bibitem += f\" \\\\textit{{{journal}}}\"\n",
    "        if volume:\n",
    "            bibitem += f\", {volume}\"\n",
    "        if pages:\n",
    "            bibitem += f\", {pages}\"\n",
    "    elif entry_type == \"inproceedings\":\n",
    "        if booktitle:\n",
    "            bibitem += f\" In \\\\textit{{{booktitle}}}\"\n",
    "        if pages:\n",
    "            bibitem += f\", pp. {pages}\"\n",
    "        if organization:\n",
    "            bibitem += f\". {organization}\"\n",
    "    elif entry_type == \"misc\":\n",
    "        if note:\n",
    "            bibitem += f\" {note}\"\n",
    "    \n",
    "    if year:\n",
    "        bibitem += f\", {year}\"\n",
    "    if publisher:\n",
    "        bibitem += f\". {publisher}\"\n",
    "    if url:\n",
    "        bibitem += f\". \\\\url{{{url}}}\"\n",
    "\n",
    "    return bibitem.strip(\" .\") + \".\"\n",
    "\n",
    "# === MAIN EXECUTION ===\n",
    "\n",
    "bib_path = \"bibliography.bib\"\n",
    "assert os.path.exists(bib_path), f\"Can't find {bib_path}\"\n",
    "\n",
    "with open(bib_path, \"r\", encoding=\"utf-8\") as bibfile:\n",
    "    bibtex_str = bibfile.read()\n",
    "\n",
    "parser = BibTexParser(common_strings=True)\n",
    "parser.customization = homogenize_latex_encoding\n",
    "bib_database = bibtexparser.loads(bibtex_str, parser=parser)\n",
    "\n",
    "bibitems = [format_entry(entry) for entry in bib_database.entries]\n",
    "bibitems_text = \"\\\\begin{thebibliography}{99}\\n\" + \"\\n\\n\".join(bibitems) + \"\\n\\\\end{thebibliography}\"\n",
    "\n",
    "with open(\"generated_bibitems.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(bibitems_text)\n",
    "\n",
    "print(\"✅ All entries written to generated_bibitems.tex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9272eabe-5b76-4f78-93a2-a5d800ce3c25",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'main.tex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbibtexparser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustomization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m homogenize_latex_encoding\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain.tex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m     tex \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      8\u001b[0m cited_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcite\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m([^}]+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m, tex))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'main.tex'"
     ]
    }
   ],
   "source": [
    "from bibtexparser.bparser import BibTexParser\n",
    "from bibtexparser.customization import homogenize_latex_encoding\n",
    "import re\n",
    "\n",
    "with open(\"main.tex\") as f:\n",
    "    tex = f.read()\n",
    "\n",
    "cited_keys = set(re.findall(r'\\\\cite\\w*\\{([^}]+)\\}', tex))\n",
    "cited_keys = {k.strip() for key in cited_keys for k in key.split(',')}\n",
    "\n",
    "with open(\"bibliography.bib\") as f:\n",
    "    parser = BibTexParser(common_strings=True)\n",
    "    parser.customization = homogenize_latex_encoding\n",
    "    db = bibtexparser.load(f, parser=parser)\n",
    "\n",
    "filtered_entries = [entry for entry in db.entries if entry['ID'] in cited_keys]\n",
    "db.entries = filtered_entries\n",
    "\n",
    "with open(\"cleaned.bib\", \"w\") as f:\n",
    "    f.write(bibtexparser.dumps(db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc4b2b37-8faf-4f0f-90a5-8600c7627b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Simulate input from user as a long LaTeX bibliography string\n",
    "with open(\"generated_bibitems.tex\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tex_content = f.read()\n",
    "\n",
    "# Extract all citation keys from \\bibitem{key}\n",
    "keys = re.findall(r\"\\\\bibitem\\{(.*?)\\}\", tex_content)\n",
    "\n",
    "# Count duplicates\n",
    "key_counts = Counter(keys)\n",
    "duplicates = {k: v for k, v in key_counts.items() if v > 1}\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c854062-f662-4098-99d9-9786ea77238e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
